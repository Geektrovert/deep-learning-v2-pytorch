{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Fashion-MNIST\n",
    "\n",
    "Now it's your turn to build and train a neural network. You'll be using the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), a drop-in replacement for the MNIST dataset. MNIST is actually quite trivial with neural networks where you can easily achieve better than 97% accuracy. Fashion-MNIST is a set of 28x28 greyscale images of clothes. It's more complex than MNIST, so it's a better representation of the actual performance of your network, and a better representation of datasets you'll use in the real world.\n",
    "\n",
    "<img src='assets/fashion-mnist-sprite.png' width=500px>\n",
    "\n",
    "In this notebook, you'll build your own neural network. For the most part, you could just copy and paste the code from Part 3, but you wouldn't be learning. It's important for you to write the code yourself and get it to work. Feel free to consult the previous notebooks though as you work through this.\n",
    "\n",
    "First off, let's load the dataset through torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /Users/samnan/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 26394624/26421880 [03:17<00:00, 154386.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/samnan/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /Users/samnan/.pytorch/F_MNIST_data/FashionMNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /Users/samnan/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/29515 [00:00<?, ?it/s]\u001b[A\n",
      " 56%|█████▌    | 16384/29515 [00:00<00:00, 81488.19it/s]\u001b[A\n",
      "32768it [00:00, 43540.48it/s]                           \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/samnan/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /Users/samnan/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /Users/samnan/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4422102 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 16384/4422102 [00:00<00:55, 79233.16it/s]\u001b[A\n",
      "  1%|          | 49152/4422102 [00:00<00:46, 94055.99it/s]\u001b[A\n",
      "  2%|▏         | 106496/4422102 [00:01<00:36, 118049.75it/s]\u001b[A\n",
      "  5%|▍         | 212992/4422102 [00:01<00:28, 146449.93it/s]\u001b[A\n",
      " 11%|█         | 475136/4422102 [00:01<00:19, 199727.44it/s]\u001b[A\n",
      " 14%|█▍        | 622592/4422102 [00:01<00:14, 269370.69it/s]\u001b[A\n",
      " 16%|█▌        | 704512/4422102 [00:01<00:11, 327894.00it/s]\u001b[A\n",
      " 18%|█▊        | 786432/4422102 [00:02<00:12, 280354.86it/s]\u001b[A\n",
      " 20%|██        | 892928/4422102 [00:02<00:09, 356139.37it/s]\u001b[A\n",
      " 24%|██▍       | 1056768/4422102 [00:02<00:07, 462595.28it/s]\u001b[A\n",
      " 26%|██▌       | 1155072/4422102 [00:02<00:08, 388173.29it/s]\u001b[A\n",
      " 28%|██▊       | 1236992/4422102 [00:02<00:07, 444497.84it/s]\u001b[A\n",
      " 30%|███       | 1335296/4422102 [00:02<00:05, 521749.45it/s]\u001b[A\n",
      " 32%|███▏      | 1417216/4422102 [00:03<00:07, 423491.08it/s]\u001b[A\n",
      " 34%|███▎      | 1482752/4422102 [00:03<00:07, 394797.98it/s]\u001b[A\n",
      " 35%|███▍      | 1540096/4422102 [00:03<00:10, 285000.77it/s]\u001b[A\n",
      " 36%|███▌      | 1589248/4422102 [00:04<00:12, 218212.19it/s]\u001b[A\n",
      " 37%|███▋      | 1630208/4422102 [00:04<00:13, 207880.58it/s]\u001b[A\n",
      " 38%|███▊      | 1662976/4422102 [00:04<00:13, 198932.18it/s]\u001b[A\n",
      " 38%|███▊      | 1695744/4422102 [00:04<00:14, 187154.22it/s]\u001b[A\n",
      " 39%|███▉      | 1720320/4422102 [00:05<00:23, 115615.33it/s]\u001b[A\n",
      " 40%|████      | 1777664/4422102 [00:05<00:18, 140953.64it/s]\u001b[A\n",
      " 41%|████      | 1802240/4422102 [00:05<00:20, 126076.46it/s]\u001b[A\n",
      " 41%|████▏     | 1826816/4422102 [00:05<00:20, 125869.26it/s]\u001b[A\n",
      " 42%|████▏     | 1843200/4422102 [00:05<00:21, 117991.70it/s]\u001b[A\n",
      " 42%|████▏     | 1859584/4422102 [00:06<00:24, 105008.25it/s]\u001b[A\n",
      " 42%|████▏     | 1875968/4422102 [00:06<00:26, 97519.61it/s] \u001b[A\n",
      " 43%|████▎     | 1900544/4422102 [00:06<00:24, 104164.64it/s]\u001b[A\n",
      " 43%|████▎     | 1916928/4422102 [00:06<00:25, 96978.35it/s] \u001b[A\n",
      " 44%|████▍     | 1941504/4422102 [00:06<00:23, 103927.58it/s]\u001b[A\n",
      " 44%|████▍     | 1957888/4422102 [00:07<00:25, 97182.99it/s] \u001b[A\n",
      " 45%|████▍     | 1982464/4422102 [00:07<00:23, 103807.87it/s]\u001b[A\n",
      " 45%|████▌     | 2007040/4422102 [00:07<00:22, 109224.72it/s]\u001b[A\n",
      " 46%|████▌     | 2023424/4422102 [00:07<00:24, 99935.46it/s] \u001b[A\n",
      " 46%|████▋     | 2048000/4422102 [00:07<00:22, 106045.53it/s]\u001b[A\n",
      " 47%|████▋     | 2064384/4422102 [00:08<00:27, 85937.54it/s] \u001b[A\n",
      " 47%|████▋     | 2080768/4422102 [00:08<00:25, 90559.72it/s]\u001b[A\n",
      " 48%|████▊     | 2105344/4422102 [00:08<00:22, 103564.91it/s]\u001b[A\n",
      " 48%|████▊     | 2121728/4422102 [00:08<00:24, 94433.00it/s] \u001b[A\n",
      " 48%|████▊     | 2138112/4422102 [00:08<00:26, 85893.34it/s]\u001b[A\n",
      " 49%|████▊     | 2154496/4422102 [00:09<00:26, 85058.46it/s]\u001b[A\n",
      " 49%|████▉     | 2170880/4422102 [00:09<00:28, 78461.60it/s]\u001b[A\n",
      " 49%|████▉     | 2187264/4422102 [00:09<00:36, 61753.29it/s]\u001b[A\n",
      " 50%|████▉     | 2195456/4422102 [00:09<00:41, 54208.84it/s]\u001b[A\n",
      " 50%|████▉     | 2203648/4422102 [00:10<00:40, 54263.50it/s]\u001b[A\n",
      " 50%|█████     | 2211840/4422102 [00:10<00:40, 54149.45it/s]\u001b[A\n",
      " 50%|█████     | 2220032/4422102 [00:10<00:43, 50047.93it/s]\u001b[A\n",
      " 50%|█████     | 2228224/4422102 [00:10<01:01, 35426.30it/s]\u001b[A\n",
      " 51%|█████     | 2244608/4422102 [00:11<00:50, 42908.39it/s]\u001b[A\n",
      " 51%|█████     | 2252800/4422102 [00:11<00:43, 49886.03it/s]\u001b[A\n",
      " 51%|█████     | 2260992/4422102 [00:11<00:45, 47256.39it/s]\u001b[A\n",
      "26427392it [03:30, 154386.61it/s]                              \n",
      " 51%|█████▏    | 2277376/4422102 [00:11<00:49, 42919.92it/s]\u001b[A\n",
      " 52%|█████▏    | 2293760/4422102 [00:11<00:42, 50225.31it/s]\u001b[A\n",
      " 52%|█████▏    | 2301952/4422102 [00:12<00:44, 47449.78it/s]\u001b[A\n",
      " 52%|█████▏    | 2310144/4422102 [00:12<00:46, 45222.52it/s]\u001b[A\n",
      " 53%|█████▎    | 2326528/4422102 [00:12<00:48, 43438.39it/s]\u001b[A\n",
      " 53%|█████▎    | 2334720/4422102 [00:12<00:48, 43385.12it/s]\u001b[A\n",
      " 53%|█████▎    | 2342912/4422102 [00:13<00:49, 42425.65it/s]\u001b[A\n",
      " 53%|█████▎    | 2359296/4422102 [00:13<00:41, 49384.64it/s]\u001b[A\n",
      " 54%|█████▎    | 2367488/4422102 [00:13<00:43, 46891.75it/s]\u001b[A\n",
      " 54%|█████▍    | 2383872/4422102 [00:13<00:37, 54018.12it/s]\u001b[A\n",
      " 54%|█████▍    | 2392064/4422102 [00:13<00:40, 49565.98it/s]\u001b[A\n",
      " 54%|█████▍    | 2400256/4422102 [00:14<00:42, 47130.43it/s]\u001b[A\n",
      " 55%|█████▍    | 2416640/4422102 [00:14<00:37, 53850.22it/s]\u001b[A\n",
      " 55%|█████▍    | 2424832/4422102 [00:14<00:54, 36912.23it/s]\u001b[A\n",
      " 55%|█████▌    | 2441216/4422102 [00:14<00:44, 44057.05it/s]\u001b[A\n",
      " 55%|█████▌    | 2449408/4422102 [00:15<01:00, 32724.99it/s]\u001b[A\n",
      " 56%|█████▌    | 2465792/4422102 [00:15<00:48, 39933.71it/s]\u001b[A\n",
      " 56%|█████▌    | 2473984/4422102 [00:15<01:02, 31237.11it/s]\u001b[A\n",
      " 56%|█████▌    | 2482176/4422102 [00:16<01:25, 22804.71it/s]\u001b[A\n",
      " 56%|█████▋    | 2490368/4422102 [00:16<01:26, 22275.31it/s]\u001b[A\n",
      " 57%|█████▋    | 2498560/4422102 [00:17<01:14, 25923.93it/s]\u001b[A\n",
      " 57%|█████▋    | 2506752/4422102 [00:17<01:19, 24119.95it/s]\u001b[A\n",
      " 57%|█████▋    | 2514944/4422102 [00:17<01:09, 27633.19it/s]\u001b[A\n",
      " 57%|█████▋    | 2531328/4422102 [00:17<00:54, 34473.71it/s]\u001b[A\n",
      " 57%|█████▋    | 2539520/4422102 [00:18<00:58, 31972.32it/s]\u001b[A\n",
      " 58%|█████▊    | 2555904/4422102 [00:18<00:50, 36898.18it/s]\u001b[A\n",
      " 58%|█████▊    | 2564096/4422102 [00:18<00:48, 38196.59it/s]\u001b[A\n",
      " 58%|█████▊    | 2572288/4422102 [00:18<00:41, 44945.21it/s]\u001b[A\n",
      " 59%|█████▊    | 2588672/4422102 [00:19<00:38, 47856.29it/s]\u001b[A\n",
      " 59%|█████▊    | 2596864/4422102 [00:19<00:33, 54208.60it/s]\u001b[A\n",
      " 59%|█████▉    | 2613248/4422102 [00:19<00:29, 60610.21it/s]\u001b[A\n",
      " 59%|█████▉    | 2629632/4422102 [00:19<00:30, 59006.56it/s]\u001b[A\n",
      " 60%|█████▉    | 2637824/4422102 [00:19<00:27, 64337.84it/s]\u001b[A\n",
      " 60%|██████    | 2654208/4422102 [00:19<00:25, 68408.98it/s]\u001b[A\n",
      " 60%|██████    | 2670592/4422102 [00:20<00:24, 70831.58it/s]\u001b[A\n",
      " 61%|██████    | 2686976/4422102 [00:20<00:23, 73503.96it/s]\u001b[A\n",
      " 61%|██████    | 2703360/4422102 [00:20<00:22, 76424.72it/s]\u001b[A\n",
      " 62%|██████▏   | 2727936/4422102 [00:20<00:20, 84539.19it/s]\u001b[A\n",
      " 62%|██████▏   | 2744320/4422102 [00:20<00:19, 85798.61it/s]\u001b[A\n",
      " 63%|██████▎   | 2777088/4422102 [00:21<00:16, 100587.32it/s]\u001b[A\n",
      " 63%|██████▎   | 2801664/4422102 [00:21<00:14, 110258.72it/s]\u001b[A\n",
      " 64%|██████▍   | 2842624/4422102 [00:21<00:12, 125658.86it/s]\u001b[A\n",
      " 65%|██████▌   | 2875392/4422102 [00:21<00:13, 111900.96it/s]\u001b[A\n",
      " 67%|██████▋   | 2949120/4422102 [00:22<00:10, 141937.89it/s]\u001b[A\n",
      " 68%|██████▊   | 2990080/4422102 [00:22<00:09, 156783.46it/s]\u001b[A\n",
      " 69%|██████▊   | 3031040/4422102 [00:22<00:08, 164952.89it/s]\u001b[A\n",
      " 69%|██████▉   | 3063808/4422102 [00:22<00:07, 172325.26it/s]\u001b[A\n",
      " 70%|███████   | 3104768/4422102 [00:22<00:07, 182028.16it/s]\u001b[A\n",
      " 71%|███████   | 3145728/4422102 [00:23<00:05, 218064.97it/s]\u001b[A\n",
      " 72%|███████▏  | 3178496/4422102 [00:23<00:05, 218526.19it/s]\u001b[A\n",
      " 73%|███████▎  | 3211264/4422102 [00:23<00:08, 149952.13it/s]\u001b[A\n",
      " 74%|███████▍  | 3276800/4422102 [00:23<00:06, 184946.06it/s]\u001b[A\n",
      " 75%|███████▍  | 3309568/4422102 [00:23<00:06, 179520.44it/s]\u001b[A\n",
      " 76%|███████▌  | 3342336/4422102 [00:24<00:06, 175532.42it/s]\u001b[A\n",
      " 76%|███████▋  | 3375104/4422102 [00:24<00:05, 203001.82it/s]\u001b[A\n",
      " 77%|███████▋  | 3399680/4422102 [00:24<00:05, 197132.94it/s]\u001b[A\n",
      " 77%|███████▋  | 3424256/4422102 [00:24<00:05, 183269.13it/s]\u001b[A\n",
      " 78%|███████▊  | 3457024/4422102 [00:24<00:04, 208275.89it/s]\u001b[A\n",
      " 79%|███████▊  | 3481600/4422102 [00:24<00:04, 201569.30it/s]\u001b[A\n",
      " 79%|███████▉  | 3514368/4422102 [00:24<00:04, 203456.57it/s]\u001b[A\n",
      " 80%|████████  | 3547136/4422102 [00:24<00:03, 225808.65it/s]\u001b[A\n",
      " 81%|████████  | 3571712/4422102 [00:25<00:03, 213992.90it/s]\u001b[A\n",
      " 82%|████████▏ | 3604480/4422102 [00:25<00:03, 211659.40it/s]\u001b[A\n",
      " 82%|████████▏ | 3645440/4422102 [00:25<00:03, 246330.43it/s]\u001b[A\n",
      " 83%|████████▎ | 3678208/4422102 [00:25<00:03, 246306.92it/s]\u001b[A\n",
      " 84%|████████▍ | 3710976/4422102 [00:25<00:03, 215235.90it/s]\u001b[A\n",
      " 85%|████████▍ | 3743744/4422102 [00:25<00:03, 214009.79it/s]\u001b[A\n",
      " 86%|████████▌ | 3784704/4422102 [00:25<00:02, 249321.74it/s]\u001b[A\n",
      " 86%|████████▋ | 3817472/4422102 [00:26<00:02, 243356.10it/s]\u001b[A\n",
      " 87%|████████▋ | 3850240/4422102 [00:26<00:02, 215483.08it/s]\u001b[A\n",
      " 88%|████████▊ | 3891200/4422102 [00:26<00:02, 220375.17it/s]\u001b[A\n",
      " 89%|████████▉ | 3932160/4422102 [00:26<00:02, 225020.82it/s]\u001b[A\n",
      " 90%|████████▉ | 3973120/4422102 [00:26<00:01, 256315.89it/s]\u001b[A\n",
      " 91%|█████████ | 4005888/4422102 [00:26<00:01, 247732.04it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 4038656/4422102 [00:27<00:01, 221977.07it/s]\u001b[A\n",
      " 92%|█████████▏| 4063232/4422102 [00:27<00:01, 218723.51it/s]\u001b[A\n",
      " 92%|█████████▏| 4087808/4422102 [00:27<00:01, 224589.93it/s]\u001b[A\n",
      " 93%|█████████▎| 4120576/4422102 [00:27<00:01, 233886.70it/s]\u001b[A\n",
      " 94%|█████████▍| 4161536/4422102 [00:27<00:01, 238619.61it/s]\u001b[A\n",
      " 95%|█████████▍| 4186112/4422102 [00:27<00:01, 234050.76it/s]\u001b[A\n",
      " 95%|█████████▌| 4218880/4422102 [00:28<00:01, 167660.97it/s]\u001b[A\n",
      " 97%|█████████▋| 4292608/4422102 [00:28<00:00, 208174.76it/s]\u001b[A\n",
      " 98%|█████████▊| 4325376/4422102 [00:28<00:00, 193927.01it/s]\u001b[A\n",
      " 99%|█████████▊| 4358144/4422102 [00:28<00:00, 170730.37it/s]\u001b[A\n",
      " 99%|█████████▉| 4382720/4422102 [00:28<00:00, 130911.83it/s]\u001b[A\n",
      "100%|█████████▉| 4415488/4422102 [00:29<00:00, 158117.36it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/samnan/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /Users/samnan/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /Users/samnan/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "8192it [00:01, 39469.05it/s]            \u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/samnan/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /Users/samnan/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import helper\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Here you should define your network. As with MNIST, each image is 28x28 which is a total of 784 pixels, and there are 10 classes. You should include at least one hidden layer. We suggest you use ReLU activations for the layers and to return the logits or log-softmax from the forward pass. It's up to you how many layers you add and the size of those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your network architecture here\n",
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 256),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(256, 128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128, 64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(64, 10),\n",
    "                        nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "Now you should create your network and train it. First you'll want to define [the criterion](http://pytorch.org/docs/master/nn.html#loss-functions) ( something like `nn.CrossEntropyLoss`) and [the optimizer](http://pytorch.org/docs/master/optim.html) (typically `optim.SGD` or `optim.Adam`).\n",
    "\n",
    "Then write the training code. Remember the training pass is a fairly straightforward process:\n",
    "\n",
    "* Make a forward pass through the network to get the logits \n",
    "* Use the logits to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "By adjusting the hyperparameters (hidden units, learning rate, etc), you should be able to get the training loss below 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the network, define the criterion and optimizer\n",
    "from torch import optim\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.508199263594425\n",
      "Training loss: 0.38886052692559225\n",
      "Training loss: 0.3541007466090005\n",
      "Training loss: 0.33373748367306777\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train the network here\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "\n",
    "# Test out your network!\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.resize_(1, 784)\n",
    "\n",
    "# TODO: Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "ps = torch.exp(logps)\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
